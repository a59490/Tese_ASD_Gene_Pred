{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('final_dataset.csv',header=None)\n",
    "\n",
    "X=dataset[3].copy()\n",
    "X = X.str.split(expand=True)\n",
    "\n",
    "Y = dataset[4].copy()\n",
    "Y = Y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1155\n",
      "0    1095\n",
      "Name: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "        ...   \n",
       "763    float64\n",
       "764    float64\n",
       "765    float64\n",
       "766    float64\n",
       "767    float64\n",
       "Length: 768, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = X.astype(float)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "less values that expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, X, Y):\n",
    "    sensitivity_scorer = make_scorer(recall_score)\n",
    "    specificity_scorer = make_scorer(recall_score, pos_label=0)\n",
    "    MCC=make_scorer(matthews_corrcoef)\n",
    "\n",
    "\n",
    "    scoring = {'AUC': 'roc_auc', 'Accuracy': \"accuracy\", \"f1\": \"f1\",\n",
    "                        \"Recall\": \"recall\", \"Precision\": \"precision\",\"MCC\":MCC, \"Average Precision\": \"average_precision\",\n",
    "                        \"Sensitivity\": sensitivity_scorer, \"Specificity\": specificity_scorer}\n",
    "\n",
    "    scores=cross_validate(model, X, Y, scoring=scoring)\n",
    "\n",
    "    mean_scores = {metric: values.mean() for metric, values in scores.items()}\n",
    "\n",
    "    mean_scores_df = pd.DataFrame(list(mean_scores.items()), columns=['Metric', 'Mean Score'])\n",
    "\n",
    "    return mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all scalers \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.443960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.013663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.706754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.668612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.677922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.660103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.310588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.719594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.677922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.631963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    0.443960\n",
       "1               score_time    0.013663\n",
       "2                 test_AUC    0.706754\n",
       "3            test_Accuracy    0.655556\n",
       "4                  test_f1    0.668612\n",
       "5              test_Recall    0.677922\n",
       "6           test_Precision    0.660103\n",
       "7                 test_MCC    0.310588\n",
       "8   test_Average Precision    0.719594\n",
       "9         test_Sensitivity    0.677922\n",
       "10        test_Specificity    0.631963"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=MinMaxScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "lr_scores=cross_val(lr,X_scaled,Y)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>28.783056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.028528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.723303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.670222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.675153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.667532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.683322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.340656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.724390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.667532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.673059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time   28.783056\n",
       "1               score_time    0.028528\n",
       "2                 test_AUC    0.723303\n",
       "3            test_Accuracy    0.670222\n",
       "4                  test_f1    0.675153\n",
       "5              test_Recall    0.667532\n",
       "6           test_Precision    0.683322\n",
       "7                 test_MCC    0.340656\n",
       "8   test_Average Precision    0.724390\n",
       "9         test_Sensitivity    0.667532\n",
       "10        test_Specificity    0.673059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "lr=LogisticRegressionCV(max_iter=10000)\n",
    "lr_scores=cross_val(lr,X,Y)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>3.063211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.714962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.669930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.684301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.337004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.724908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.679452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    3.063211\n",
       "1               score_time    0.029622\n",
       "2                 test_AUC    0.714962\n",
       "3            test_Accuracy    0.668000\n",
       "4                  test_f1    0.669930\n",
       "5              test_Recall    0.657143\n",
       "6           test_Precision    0.684301\n",
       "7                 test_MCC    0.337004\n",
       "8   test_Average Precision    0.724908\n",
       "9         test_Sensitivity    0.657143\n",
       "10        test_Specificity    0.679452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LGBMClassifier(verbose=-1,number_estimators=1000,learning_rate=0.1)\n",
    "\n",
    "lg_scores=cross_val(lg,X,Y)\n",
    "lg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>2.433424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.050693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.706790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.651478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.631169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.673440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.308129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.713623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.631169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.676712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    2.433424\n",
       "1               score_time    0.050693\n",
       "2                 test_AUC    0.706790\n",
       "3            test_Accuracy    0.653333\n",
       "4                  test_f1    0.651478\n",
       "5              test_Recall    0.631169\n",
       "6           test_Precision    0.673440\n",
       "7                 test_MCC    0.308129\n",
       "8   test_Average Precision    0.713623\n",
       "9         test_Sensitivity    0.631169\n",
       "10        test_Specificity    0.676712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores=cross_val(rf,X,Y)\n",
    "rf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "{'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# import gridsearchcv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a dictionary of parameters\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# create Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "rf_gscv = GridSearchCV(estimator=rf_model,\n",
    "                       param_grid=param_grid,\n",
    "                       scoring='accuracy',\n",
    "                       cv=5,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit the gridsearch\n",
    "rf_gscv.fit(X, Y)\n",
    "\n",
    "# Get the best parameters\n",
    "\n",
    "rf_gscv.best_params_\n",
    "\n",
    "# get the values of best parameters\n",
    "best_params = rf_gscv.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores=cross_val(rf,X,Y)\n",
    "rf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.851723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.642086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.718302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.651556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.638261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.682523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.307472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.723851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.705936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    0.851723\n",
       "1               score_time    0.642086\n",
       "2                 test_AUC    0.718302\n",
       "3            test_Accuracy    0.651556\n",
       "4                  test_f1    0.638261\n",
       "5              test_Recall    0.600000\n",
       "6           test_Precision    0.682523\n",
       "7                 test_MCC    0.307472\n",
       "8   test_Average Precision    0.723851\n",
       "9         test_Sensitivity    0.600000\n",
       "10        test_Specificity    0.705936"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc_scores=cross_val(svc,X,Y)\n",
    "svc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sydromic = pd.read_csv('sfari_ed_01_16_2024.csv')\n",
    "#sydromic = sydromic[pd.isna(sydromic['gene-score'])].copy() # df with only syndromic genes with no gene score\n",
    "\n",
    "sfari=pd.read_csv('sfari_ed_01_16_2024.csv')\n",
    "sfari=sfari[sfari['gene-score'] == 1] # df with only sfari E1 genes\n",
    "\n",
    "#sfari= pd.concat([sydromic,sfari],ignore_index=True) # df with both syndromic and sfari E1 genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1=pd.read_csv('final_dataset.csv',header=None)\n",
    "\n",
    "#merge the two datasets by ensembl id\n",
    "\n",
    "E1_dataset=pd.merge(E1,sfari,left_on=1,right_on='ensembl-id')\n",
    "E1_dataset=E1_dataset[[0,1,2,3,4]]\n",
    "\n",
    "test_dataset=pd.read_csv('final_dataset.csv',header=None)\n",
    "test_dataset=test_dataset[test_dataset[4]==0]\n",
    "\n",
    "#concatenate the two datasets\n",
    "test_dataset=pd.concat([test_dataset,E1_dataset],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_E1=test_dataset[3].copy()\n",
    "X_E1 = X_E1.str.split(expand=True)\n",
    "X_E1 = X_E1.astype(float)\n",
    "\n",
    "\n",
    "Y_E1 = test_dataset[4].copy()\n",
    "Y_E1 = Y_E1.astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1095\n",
       "1     232\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_E1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores with E1 and Syd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>8.680138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.024363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.779750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.592973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.702657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.513409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.457650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.588279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.702657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.802740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    8.680138\n",
       "1               score_time    0.024363\n",
       "2                 test_AUC    0.813788\n",
       "3            test_Accuracy    0.779750\n",
       "4                  test_f1    0.592973\n",
       "5              test_Recall    0.702657\n",
       "6           test_Precision    0.513409\n",
       "7                 test_MCC    0.457650\n",
       "8   test_Average Precision    0.588279\n",
       "9         test_Sensitivity    0.702657\n",
       "10        test_Specificity    0.802740"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr=LogisticRegressionCV(max_iter=10000,class_weight='balanced')\n",
    "lr_scores=cross_val(lr,X_E1,Y_E1)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores with only E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>7.756386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.024322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_AUC</td>\n",
       "      <td>0.845519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Accuracy</td>\n",
       "      <td>0.860613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.507714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_Recall</td>\n",
       "      <td>0.423404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_Precision</td>\n",
       "      <td>0.648567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_MCC</td>\n",
       "      <td>0.447558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_Average Precision</td>\n",
       "      <td>0.573722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_Sensitivity</td>\n",
       "      <td>0.423404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_Specificity</td>\n",
       "      <td>0.953425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Mean Score\n",
       "0                 fit_time    7.756386\n",
       "1               score_time    0.024322\n",
       "2                 test_AUC    0.845519\n",
       "3            test_Accuracy    0.860613\n",
       "4                  test_f1    0.507714\n",
       "5              test_Recall    0.423404\n",
       "6           test_Precision    0.648567\n",
       "7                 test_MCC    0.447558\n",
       "8   test_Average Precision    0.573722\n",
       "9         test_Sensitivity    0.423404\n",
       "10        test_Specificity    0.953425"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr=LogisticRegressionCV(max_iter=10000)\n",
    "lr_scores=cross_val(lr,X_E1,Y_E1)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
